{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a76cf7af",
   "metadata": {},
   "source": [
    "# Sudo code:\n",
    "### Process to obtain the data:\n",
    "1. Get the number of posts.\n",
    "    * define city name.\n",
    "    * create url with get_url function\n",
    "    * requests.get(url) to get response\n",
    "    * use BeautifuSoup to get entire posts text\n",
    "    * Find total number of posts then return \n",
    "2. Use the total number of posts to get each pages first post number (119 posts per page)\n",
    "    * List name pages e.g. [0, 120, 240, 360, ........]\n",
    "3. Scrape the information I need and store in the list\n",
    "    * loop each pages list, it opens the page starting with the posts number\n",
    "    * Create function to obtain informations.\n",
    "        This will scrape each post, then store the information. \n",
    "4. Creat DataFrame with the information I scraped.\n",
    "    * Store in the list of empty DataFrames \n",
    "    * Save as csv file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547ae389",
   "metadata": {},
   "source": [
    "#### Sub_city List:\n",
    "* sub_city_van_area: \n",
    "        * 'van'- Vancouver\n",
    "        * 'bnc' - Burnaby/NewWest\n",
    "        * 'rds' - Delta/Surrey/Langley\n",
    "        * 'nvn' - North Shore\n",
    "        * 'rch' - Richmond\n",
    "        * 'pml' - Tricities/Pittmedow/Maple Ridge\n",
    "* sub_city_tor_area: \n",
    "        * 'tor' - City of Toronto\n",
    "        * 'bra' - Brampton\n",
    "        * 'drh' - Durham Region\n",
    "        * 'mss' - Mississauga\n",
    "        * 'oak' - Oakville\n",
    "        * 'yrk' - York Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68b4a37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def get_search_number(url, city, sub_city):\n",
    "    response = get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    posts = soup.find_all('li', class_='result-row')\n",
    "    results_num = soup.find('div', class_='search-legend')\n",
    "    results_total = int(results_num.find('span', class_='totalcount').text)\n",
    "    print(f\"Total number of search result in {city} - {sub_city}: {results_total}\")\n",
    "    return results_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4ad61b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Url:\n",
    "    def __init__(self, city_name, sub_city=None, num_post=0):\n",
    "        self.city_name = city_name\n",
    "        self.sub_city = sub_city\n",
    "        self.num_post = num_post\n",
    "        self.url = self.get_url()\n",
    "        \n",
    "    def get_url(self):\n",
    "        if self.city_name == 'Abbotsford':\n",
    "            url = f'https://{self.city_name.lower()}.craigslist.org/search/apa?s={self.num_post}sort=date&bundleDuplicates=1&min_price=99max_price=&availabilityMode=0&sale_date=all+dates'\n",
    "        else:\n",
    "            url = f'https://{self.city_name.lower()}.craigslist.org/search/{self.sub_city}/apa?s={self.num_post}sort=date&bundleDuplicates=1&min_price=99max_price=&availabilityMode=0&sale_date=all+dates'\n",
    "        return url   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "681acd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of search result in Vancouver - van: 3000\n",
      "Total Number of post scraped: 3052\n",
      "Total number of search result in Vancouver - bnc: 1296\n",
      "Total Number of post scraped: 1318\n",
      "Total number of search result in Vancouver - rds: 1810\n",
      "Total Number of post scraped: 1845\n",
      "Total number of search result in Vancouver - nvn: 743\n",
      "Total Number of post scraped: 774\n",
      "Total number of search result in Vancouver - rch: 368\n",
      "Total Number of post scraped: 383\n",
      "Total number of search result in Vancouver - pml: 847\n",
      "Total Number of post scraped: 852\n",
      "Total number of search result in Toronto - tor: 3000\n",
      "Total Number of post scraped: 3033\n",
      "Total number of search result in Toronto - bra: 55\n",
      "Total Number of post scraped: 55\n",
      "Total number of search result in Toronto - drh: 46\n",
      "Total Number of post scraped: 46\n",
      "Total number of search result in Toronto - mss: 241\n",
      "Total Number of post scraped: 241\n",
      "Total number of search result in Toronto - oak: 9\n",
      "Total Number of post scraped: 61\n",
      "Total number of search result in Toronto - yrk: 108\n",
      "Total Number of post scraped: 108\n",
      "CPU times: total: 19.7 s\n",
      "Wall time: 3min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "city_names = [\"Vancouver\", \"Toronto\"]\n",
    "dfs = []\n",
    "for city in city_names:\n",
    "    if city == 'Vancouver':\n",
    "        sub_city_names = ['van', 'bnc', 'rds', 'nvn', 'rch', 'pml']\n",
    "    elif city == 'Toronto':\n",
    "        sub_city_names = ['tor', 'bra', 'drh', 'mss', 'oak', 'yrk']\n",
    "    for sub_city in sub_city_names:\n",
    "        url = Url(city, sub_city)\n",
    "        url_ = url.url\n",
    "        results_total = get_search_number(url_, city, sub_city)\n",
    "        \n",
    "        pages = np.arange(0, results_total+1, 120)\n",
    "        \n",
    "        iterations = 0\n",
    "\n",
    "        post_date = []\n",
    "        post_cities = []\n",
    "        num_bedroom = []\n",
    "        sqfts = []\n",
    "        prices = []\n",
    "        post_titles = []\n",
    "        post_links = []\n",
    "\n",
    "        for page in pages:\n",
    "     \n",
    "            # get request\n",
    "            url = Url(city_name=city, sub_city=sub_city, num_post=page)\n",
    "            url_ = url.url\n",
    "            response = get(url_)\n",
    "    \n",
    "            sleep(1)\n",
    "    \n",
    "            # throw warning for status code that are not 200\n",
    "            if response.status_code != 200:\n",
    "                warn(f'Request: {requests}; Status code: {response.status_code}')\n",
    "        \n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "            posts = soup.find_all('li', class_='result-row')\n",
    "    \n",
    "    \n",
    "            # Extract data \n",
    "            for post in posts:\n",
    "        \n",
    "                if post.find('span', class_ = 'result-hood') is not None:\n",
    "            \n",
    "                    # Posting date\n",
    "                    post_datetime = post.find('time', class_='result-date')['datetime']\n",
    "                    post_date.append(post_datetime)\n",
    "            \n",
    "                    # Neighbourhoods\n",
    "                    post_city = post.find('span', class_='result-hood').text.strip('( )')\n",
    "                    post_cities.append(post_city)\n",
    "            \n",
    "                    # title text\n",
    "                    post_title = post.find('a', class_='result-title hdrlnk')\n",
    "                    post_title_text = post_title.text\n",
    "                    post_titles.append(post_title_text)\n",
    "            \n",
    "                    # Post price in integer\n",
    "                    price = int(post.find('span', class_='result-price').text.split('$')[1].replace(',', ''))\n",
    "                    prices.append(price)\n",
    "            \n",
    "                    # Post link\n",
    "                    post_link = post_title['href']\n",
    "                    post_links.append(post_link)\n",
    "            \n",
    "                    if post.find('span', class_ = 'housing') is not None:\n",
    "                \n",
    "                        #if the first element is accidentally square footage\n",
    "                        if 'ft2' in post.find('span', class_ = 'housing').text.split()[0]:\n",
    "                    \n",
    "                            #make bedroom nan\n",
    "                            bedroom_count = np.nan\n",
    "                            num_bedroom.append(bedroom_count)\n",
    "                    \n",
    "                            #make sqft the first element\n",
    "                            sqft = int(post.find('span', class_ = 'housing').text.split()[0][:-3])\n",
    "                            sqfts.append(sqft)\n",
    "                    \n",
    "                        #if the length of the housing details element is more than 2\n",
    "                        elif len(post.find('span', class_ = 'housing').text.split()) > 2:\n",
    "                    \n",
    "                            #therefore element 0 will be bedroom count\n",
    "                            bedroom_count = post.find('span', class_ = 'housing').text.replace(\"br\", \"\").split()[0]\n",
    "                            num_bedroom.append(bedroom_count)\n",
    "                    \n",
    "                            #and sqft will be number 3, so set these here and append\n",
    "                            sqft = int(post.find('span', class_ = 'housing').text.split()[2][:-3])\n",
    "                            sqfts.append(sqft)\n",
    "                    \n",
    "                        #if there is num bedrooms but no sqft\n",
    "                        elif len(post.find('span', class_ = 'housing').text.split()) == 2:\n",
    "                    \n",
    "                            #therefore element 0 will be bedroom count\n",
    "                            bedroom_count = post.find('span', class_ = 'housing').text.replace(\"br\", \"\").split()[0]\n",
    "                            num_bedroom.append(bedroom_count)\n",
    "                    \n",
    "                            #and sqft will be number 3, so set these here and append\n",
    "                            sqft = np.nan\n",
    "                            sqfts.append(sqft)                    \n",
    "                \n",
    "                        else:\n",
    "                            bedroom_count = np.nan\n",
    "                            num_bedroom.append(bedroom_count)\n",
    "                \n",
    "                            sqft = np.nan\n",
    "                            sqfts.append(sqft)\n",
    "                \n",
    "                    #if none of those conditions catch, make bedroom nan, this won't be needed    \n",
    "                    else:\n",
    "                        bedroom_count = np.nan\n",
    "                        num_bedroom.append(bedroom_count)\n",
    "                \n",
    "                        sqft = np.nan\n",
    "                        sqfts.append(sqft)\n",
    "                \n",
    "                iterations += 1\n",
    "        print(f\"Total Number of post scraped: {iterations}\")\n",
    "        \n",
    "        # Store in Pandas DataFrame then append to the list of DataFrame\n",
    "        df = pd.DataFrame({'Post Datetime': post_date,\n",
    "                           'Post Title': post_titles,\n",
    "                           'Post URL': post_links,\n",
    "                          'Neighborhood': post_cities,\n",
    "                          'Bedroom': num_bedroom,\n",
    "                          'SQFT': sqfts,\n",
    "                          'Price': prices})\n",
    "        \n",
    "        dfs.append(df)\n",
    "        \n",
    "        # Save DataFrame in CSV file. \n",
    "        df.to_csv(f'C:\\\\Users\\\\Masa\\\\Desktop\\\\Chilliwack Real Estate\\\\Data\\\\{city}_{sub_city}_rental_price_data.csv',\n",
    "                 header=False, mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43f1ee60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f075d403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3052\n",
      "1318\n",
      "1845\n",
      "774\n",
      "383\n",
      "852\n",
      "3033\n",
      "55\n",
      "46\n",
      "241\n",
      "18\n",
      "108\n"
     ]
    }
   ],
   "source": [
    "for df in dfs:\n",
    "    print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0762938e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1293"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As you can tell the number of scraped data is exceeding the number of the post, so I remove duplicate. \n",
    "df = pd.read_csv('C:\\\\Users\\\\Masa\\\\Desktop\\\\Chilliwack Real Estate\\\\Data\\\\Vancouver_bnc_rental_price_data.csv').drop('Unnamed: 0', axis=1)\n",
    "df.drop_duplicates(inplace=True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f6b7508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post Datetime</th>\n",
       "      <th>Post Title</th>\n",
       "      <th>Post URL</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Bedroom</th>\n",
       "      <th>SQFT</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-10 17:16</td>\n",
       "      <td>Spacious 2 bedroom Apartment with in suite lau...</td>\n",
       "      <td>https://vancouver.craigslist.org/bnc/apa/d/new...</td>\n",
       "      <td>527 Carnarvon Street, New Westminster, BC</td>\n",
       "      <td>2.0</td>\n",
       "      <td>716.0</td>\n",
       "      <td>2745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-10 17:13</td>\n",
       "      <td>Brentwood Burnaby Resort Style One Bedroom Condo</td>\n",
       "      <td>https://vancouver.craigslist.org/bnc/apa/d/bur...</td>\n",
       "      <td>4720 Lougheed Hwy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-10 17:13</td>\n",
       "      <td>Two Bedroom Apartment at SFU Burnaby</td>\n",
       "      <td>https://vancouver.craigslist.org/bnc/apa/d/two...</td>\n",
       "      <td>9060 University Crescent</td>\n",
       "      <td>2.0</td>\n",
       "      <td>927.0</td>\n",
       "      <td>2600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-10 17:00</td>\n",
       "      <td>1 bedroom modern living at The Columbia New We...</td>\n",
       "      <td>https://vancouver.craigslist.org/bnc/apa/d/new...</td>\n",
       "      <td>Brewery district</td>\n",
       "      <td>1.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>2200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-10 16:59</td>\n",
       "      <td>Rare huge FULLY FURNISHED 1 bedroom at Modello...</td>\n",
       "      <td>https://vancouver.craigslist.org/bnc/apa/d/bur...</td>\n",
       "      <td>Metrotown</td>\n",
       "      <td>1.0</td>\n",
       "      <td>760.0</td>\n",
       "      <td>2800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Post Datetime                                         Post Title  \\\n",
       "0  2022-12-10 17:16  Spacious 2 bedroom Apartment with in suite lau...   \n",
       "1  2022-12-10 17:13   Brentwood Burnaby Resort Style One Bedroom Condo   \n",
       "2  2022-12-10 17:13               Two Bedroom Apartment at SFU Burnaby   \n",
       "3  2022-12-10 17:00  1 bedroom modern living at The Columbia New We...   \n",
       "4  2022-12-10 16:59  Rare huge FULLY FURNISHED 1 bedroom at Modello...   \n",
       "\n",
       "                                            Post URL  \\\n",
       "0  https://vancouver.craigslist.org/bnc/apa/d/new...   \n",
       "1  https://vancouver.craigslist.org/bnc/apa/d/bur...   \n",
       "2  https://vancouver.craigslist.org/bnc/apa/d/two...   \n",
       "3  https://vancouver.craigslist.org/bnc/apa/d/new...   \n",
       "4  https://vancouver.craigslist.org/bnc/apa/d/bur...   \n",
       "\n",
       "                                Neighborhood  Bedroom   SQFT  Price  \n",
       "0  527 Carnarvon Street, New Westminster, BC      2.0  716.0   2745  \n",
       "1                          4720 Lougheed Hwy      1.0  535.0   2400  \n",
       "2                   9060 University Crescent      2.0  927.0   2600  \n",
       "3                           Brewery district      1.0  560.0   2200  \n",
       "4                                  Metrotown      1.0  760.0   2800  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a504a07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1293 entries, 0 to 1317\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Post Datetime  1293 non-null   object \n",
      " 1   Post Title     1293 non-null   object \n",
      " 2   Post URL       1293 non-null   object \n",
      " 3   Neighborhood   1293 non-null   object \n",
      " 4   Bedroom        1257 non-null   float64\n",
      " 5   SQFT           1090 non-null   float64\n",
      " 6   Price          1293 non-null   int64  \n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 80.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29fc7cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
