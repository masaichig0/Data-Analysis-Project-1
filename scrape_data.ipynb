{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a76cf7af",
   "metadata": {},
   "source": [
    "# Sudo code:\n",
    "\n",
    "## Loop City Names: [\"Vancouver\", \"Abbotsford\", \"Toronto\"]\n",
    "\n",
    "First loop is \"Vancouver\"\n",
    "\n",
    "    * Post numbers are obtained all of the Vancouver regions post numbers. ['van', 'bnc', 'rds', 'nvn', 'rch', 'pml']\n",
    "\n",
    "   \n",
    "\n",
    "   ### Process to obtain the data:\n",
    "    1. Get the number of posts.\n",
    "        * define city name.\n",
    "        * create url with get_url function\n",
    "        * requests.get(url) to get response\n",
    "        * use BeautifuSoup to get entire posts text\n",
    "        * Find total number of posts then return \n",
    "    2. Use the total number of posts to get each pages first post number (119 posts per page)\n",
    "        * List name pages e.g. [0, 120, 240, 360, ........]\n",
    "    3. Scrape the information I need and store in the list\n",
    "        * loop each pages list, it opens the page starting with the posts number\n",
    "        * Create function to obtain informations.\n",
    "            This will scrape each post, then store the information. \n",
    "    4. Creat DataFrame with the information I scraped.\n",
    "        * Store inthe list of empty DataFrames \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4ad61b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Url:\n",
    "    def __init__(self, city_name):\n",
    "        self.city_name = city_name\n",
    "    \n",
    "        \n",
    "    def get_url(self, num_post, sub_city=None):\n",
    "        if self.city_name == 'Abbotsford':\n",
    "            url = f'https://{self.city_name.lower()}.craigslist.org/search/apa?s={num_post}sort=date&bundleDuplicates=1&min_price=99max_price=&availabilityMode=0&sale_date=all+dates'\n",
    "        if sub_city is not None:\n",
    "            sub_city = sub_city + '/'\n",
    "            url = f'https://{self.city_name.lower()}.craigslist.org/search/{sub_city.lower()}apa?s={num_post}sort=date&bundleDuplicates=1&min_price=99max_price=&availabilityMode=0&sale_date=all+dates'\n",
    "        return url   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a4ba04a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def get_search_number(url, city):\n",
    "    response = get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    posts = soup.find_all('li', class_='result-row')\n",
    "    results_num = soup.find('div', class_='search-legend')\n",
    "    results_total = int(results_num.find('span', class_='totalcount').text)\n",
    "    print(f\"Total number of search result in {city}: {results_total}\")\n",
    "    return results_total\n",
    "\n",
    "def scrape(city, total_num_posts):\n",
    "    \"\"\"\n",
    "    city: ['Vancouver', 'Abbotsford', 'Toronto']\n",
    "    total_num_posts: Total number of posts that got in get_search_number.\n",
    "    \"\"\"\n",
    "    pages = np.arange(0, total_num_posts+1, 120)\n",
    "        \n",
    "    iterations = 0\n",
    "\n",
    "    post_date = []\n",
    "    post_cities = []\n",
    "    num_bedroom = []\n",
    "    sqfts = []\n",
    "    prices = []\n",
    "    post_titles = []\n",
    "    post_links = []\n",
    "\n",
    "    for page in pages:\n",
    "     \n",
    "        # get request\n",
    "        url = Url(city)\n",
    "        url_ = url.get_url(num_post=page)\n",
    "        response = get(url_)\n",
    "    \n",
    "        sleep(1)\n",
    "    \n",
    "        # throw warning for status code that are not 200\n",
    "        if response.status_code != 200:\n",
    "            warn(f'Request: {requests}; Status code: {response.status_code}')\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "        posts = soup.find_all('li', class_='result-row')\n",
    "    \n",
    "    \n",
    "        # Extract data \n",
    "        for post in posts:\n",
    "        \n",
    "            if post.find('span', class_ = 'result-hood') is not None:\n",
    "            \n",
    "                # Posting date\n",
    "                post_datetime = post.find('time', class_='result-date')['datetime']\n",
    "                post_date.append(post_datetime)\n",
    "            \n",
    "                # Neighbourhoods\n",
    "                post_city = post.find('span', class_='result-hood').text.strip('( )')\n",
    "                post_cities.append(post_city)\n",
    "            \n",
    "                # title text\n",
    "                post_title = post.find('a', class_='result-title hdrlnk')\n",
    "                post_title_text = post_title.text\n",
    "                post_titles.append(post_title_text)\n",
    "            \n",
    "                # Post price in integer\n",
    "                price = int(post.find('span', class_='result-price').text.split('$')[1].replace(',', ''))\n",
    "                prices.append(price)\n",
    "            \n",
    "                # Post link\n",
    "                post_link = post_title['href']\n",
    "                post_links.append(post_link)\n",
    "            \n",
    "                if post.find('span', class_ = 'housing') is not None:\n",
    "                \n",
    "                    #if the first element is accidentally square footage\n",
    "                    if 'ft2' in post.find('span', class_ = 'housing').text.split()[0]:\n",
    "                    \n",
    "                        #make bedroom nan\n",
    "                        bedroom_count = np.nan\n",
    "                        num_bedroom.append(bedroom_count)\n",
    "                    \n",
    "                        #make sqft the first element\n",
    "                        sqft = int(post.find('span', class_ = 'housing').text.split()[0][:-3])\n",
    "                        sqfts.append(sqft)\n",
    "                    \n",
    "                    #if the length of the housing details element is more than 2\n",
    "                    elif len(post.find('span', class_ = 'housing').text.split()) > 2:\n",
    "                    \n",
    "                        #therefore element 0 will be bedroom count\n",
    "                        bedroom_count = post.find('span', class_ = 'housing').text.replace(\"br\", \"\").split()[0]\n",
    "                        num_bedroom.append(bedroom_count)\n",
    "                    \n",
    "                        #and sqft will be number 3, so set these here and append\n",
    "                        sqft = int(post.find('span', class_ = 'housing').text.split()[2][:-3])\n",
    "                        sqfts.append(sqft)\n",
    "                    \n",
    "                    #if there is num bedrooms but no sqft\n",
    "                    elif len(post.find('span', class_ = 'housing').text.split()) == 2:\n",
    "                    \n",
    "                        #therefore element 0 will be bedroom count\n",
    "                        bedroom_count = post.find('span', class_ = 'housing').text.replace(\"br\", \"\").split()[0]\n",
    "                        num_bedroom.append(bedroom_count)\n",
    "                    \n",
    "                        #and sqft will be number 3, so set these here and append\n",
    "                        sqft = np.nan\n",
    "                        sqfts.append(sqft)                    \n",
    "                \n",
    "                    else:\n",
    "                        bedroom_count = np.nan\n",
    "                        num_bedroom.append(bedroom_count)\n",
    "                \n",
    "                        sqft = np.nan\n",
    "                        sqfts.append(sqft)\n",
    "                \n",
    "                #if none of those conditions catch, make bedroom nan, this won't be needed    \n",
    "                else:\n",
    "                    bedroom_count = np.nan\n",
    "                    num_bedroom.append(bedroom_count)\n",
    "                \n",
    "                    sqft = np.nan\n",
    "                    sqfts.append(sqft)\n",
    "                #    num_bedroom.append(bedroom_count)\n",
    "                \n",
    "                #    sqft = np.nan\n",
    "                #    sqfts.append(sqft)\n",
    "            iterations += 1\n",
    "    print(f'{iterations} data scraped.')\n",
    "    \n",
    "    # create DataFrame\n",
    "    df = pd.DataFrame({'Post Datetime': post_date,\n",
    "                       'Post Title': post_titles,\n",
    "                       'Post URL': post_links,\n",
    "                      'Neighborhood': post_cities,\n",
    "                      'Bedroom': num_bedroom,\n",
    "                      'SQFT': sqfts,\n",
    "                      'Price': prices})\n",
    "    return df\n",
    "    \n",
    "def num_of_posts(city_name):\n",
    "    \"\"\"\n",
    "    Get number of posts in each reagions. \n",
    "    Return: list of page_nums.\n",
    "    \"\"\"\n",
    "    page_nums = []\n",
    "    \n",
    "    if city_name == 'Abbotsford':\n",
    "        url = Url(city_name)\n",
    "        url_ = url.get_url(0)\n",
    "        print(city_name)\n",
    "        results_total = get_search_number(url_, city_name)\n",
    "        \n",
    "        df = scrape()\n",
    "        \n",
    "        page_nums.append(results_total)\n",
    "    elif city_name == 'Vancouver':\n",
    "        sub_city_names = ['van', 'bnc', 'rds', 'nvn', 'rch', 'pml']\n",
    "        for sub_city in sub_city_names: \n",
    "            url = Url(city_name)\n",
    "            url_ = url.get_url(0, sub_city)\n",
    "            print(sub_city)\n",
    "            results_total = get_search_number(url_, city_name)\n",
    "            page_nums.append(results_total)\n",
    "    elif city_name == 'Toronto':\n",
    "        sub_city_names = ['tor', 'bra', 'drh', 'mss', 'oak', 'yrk']\n",
    "        for sub_city in sub_city_names:\n",
    "            url = Url(city_name)\n",
    "            url_ = url.get_url(0, sub_city)\n",
    "            print(sub_city)\n",
    "            results_total = get_search_number(url_, city_name)\n",
    "            page_nums.append(results_total)\n",
    "    return page_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9d099d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tor\n",
      "Total number of search result in Toronto: 3000\n",
      "bra\n",
      "Total number of search result in Toronto: 56\n",
      "drh\n",
      "Total number of search result in Toronto: 47\n",
      "mss\n",
      "Total number of search result in Toronto: 242\n",
      "oak\n",
      "Total number of search result in Toronto: 9\n",
      "yrk\n",
      "Total number of search result in Toronto: 108\n"
     ]
    }
   ],
   "source": [
    "page_nums = num_of_posts('Toronto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25cd5938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3000, 1313, 1821, 733, 370, 859, 1542, 3000, 56, 46, 242, 9, 108]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52d9de76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of search result in Vancouver: 108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_search_number('https://vancouver.craigslist.org/search/van/apa?s=0sort=date&bundleDuplicates=1&min_price=99max_price=&availabilityMode=0&sale_date=all+dates', 'Vancouver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f075d403",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
